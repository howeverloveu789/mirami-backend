const fs = require("fs");
const path = require("path");
const crypto = require("crypto");
const OpenAI = require("openai");

/**
 * MIRAMI Narrative Engine â€” Q19
 * - Always load latest prompt from file
 * - No prompt cache
 * - Strong debug fingerprint
 */

const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

// ğŸ”’ æ¯æ¬¡å³æ™‚è®€ promptï¼ˆå®Œå…¨ä¸åƒ require / fs cacheï¼‰
function loadSystemPrompt() {
  const promptPath = path.join(
    __dirname,
    "../prompts/q19_p_prompt.txt"
  );

  const raw = fs.readFileSync(promptPath, {
    encoding: "utf8",
    flag: "r"
  });

  return raw;
}

// ğŸ” ç”¨ prompt å…§å®¹ç”¢ç”ŸæŒ‡ç´‹ï¼ˆä¸€çœ¼çŸ¥é“æ˜¯ä¸æ˜¯æ–°ç‰ˆï¼‰
function hashPrompt(text) {
  return crypto
    .createHash("sha256")
    .update(text)
    .digest("hex")
    .slice(0, 12);
}

async function sendToMIRAMI(varoState) {
  if (!varoState) {
    throw new Error("MIRAMI state payload missing");
  }

  // â‘  Load prompt (no cache)
  const systemPrompt = loadSystemPrompt();
  const promptHash = hashPrompt(systemPrompt);

  // ğŸ”´ HARD DEBUG â€” ä¸å¯èƒ½çœ‹éŒ¯
  console.log("========================================");
  console.log("[MIRAMI] sendToMIRAMI CALLED");
  console.log("[MIRAMI] prompt hash:", promptHash);
  console.log("[MIRAMI] prompt first line:",
    systemPrompt.split("\n")[0]
  );
  console.log("[MIRAMI] varoState keys:",
    Object.keys(varoState || {})
  );
  console.log("========================================");

  // â‘¡ Call OpenAI
  const response = await client.chat.completions.create({
    model: "gpt-4.1",
    temperature: 0.4,
    messages: [
      {
        role: "system",
        content: systemPrompt
      },
      {
        role: "user",
        content: JSON.stringify(varoState, null, 2)
      }
    ]
  });

  const content = response?.choices?.[0]?.message?.content;

  if (!content || typeof content !== "string") {
    console.error("[MIRAMI] Empty or invalid response:", response);
    throw new Error("Empty response from MIRAMI");
  }

  // â‘¢ Return â€” å–®ä¸€å‡ºå£ï¼Œçµæ§‹é–æ­»
  return {
    source: "mirami",
    prompt_hash: promptHash,
    model: "gpt-4.1",
    content: content.trim()
  };
}

module.exports = {
  sendToMIRAMI
};
